
# ---------------------------
```{r ,echo=F, eval=F}

# LIST CHUNCK HEADER OPTIONS
#
chunk_options_df <- data.frame(
  Option = c("echo=TRUE (default)", "echo=FALSE", "eval=FALSE", "include=FALSE", 'results="hide"'),
  Code_Displayed = c("Yes", "No", "Yes", "No", "Yes"),
  Code_Executed = c("Yes", "Yes", "No", "Yes", "Yes"),
  Output_Shown = c("Yes", "Yes", "No", "No", "No")
)

# Convert to flextable
chunk_options_ft <- flextable(chunk_options_df) |>
  set_header_labels(
    Option = "Option",
    Code_Displayed = "Code Displayed?",
    Code_Executed = "Code Executed?",
    Output_Shown = "Output Shown?"
  ) |>
  theme_vanilla() |> 
  autofit()
chunk_options_ft
```




## Description

```{r possum-map, echo=FALSE, out.width="70%", fig.align='center'}
  # Load data-set and visualise
  knitr::include_graphics("../images/possum_age_plot.png")

```




\newpage 
## 1. Data Loading

The data was loaded via a common function  load_datasets() ` used to load all data from  ../data/dataset.zip . See Appendix for the description. The data used for these questions is as follows: 
```{r format-possums,   eval=T}
pskim_ft = skim_flextable(possums)
pskim_ft
```




Plotting age vs Total Length (totlngth)

```{r possum-scatterplot1, eval=T}
# visualise age vs totlnght
# assuming length is in mm and age is in years
#
pPlot_age_v_lngth <- ggplot(possums, aes(x = totlngth, y = age)) +
  geom_point(color = "blue", alpha = 0.6) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
  xlim(73, 96) +  # Set x-axis limits
  xlab("Total Length (mm)") +
  ylab("Age (years)") +
  theme_minimal()
```

```{r format-possum-scatter, include=F}
ggsave("possum-scatter-plot.png", pPlot_age_v_lngth, width = 6, height = 4, dpi = 300)  # Adjust width & height

pPlot_age_v_lngth <- "
\\begin{figure}[H]
    \\centering
    \\begin{minipage}{0.5\\textwidth}  % Set to 50% of page width
        \\centering
        \\includegraphics[width=\\textwidth]{possum-scatter-plot.png}
        \\caption{Age vs. Total Length}
    \\end{minipage}
\\end{figure}
"

```
\newpage
An initial scatter plot shows  the raw data directly from the CSV file. It is a plot of age (years) vs total body length (mm) of the possums.

```{r possum-scatterplot2, eval=T}
knitr::asis_output(pPlot_age_v_lngth)
```

There is a **weak positive correlation**  seen by the regression line. This suggests a weak relationship that as total length increases, the age  increases. There is a **high degree of variability** that goes against the regression line -  some younger possums have large total lengths, and some older ones have shorter total lengths.

Additionally, the data points are widely spread, particularly at higher total lengths, suggesting that total length alone is not be a strong predictor of age. There is a high density of points is between 80–95 mm in total length. There is a high density of points between 1–6 years in age. This indicates that most possums fall within this range. 

\newpage
```{r possum-boxplots1 , eval=T}
pbox_age <- ggplot(possums, aes(x = "", y = age)) + 
  geom_boxplot(fill = "lightblue", outlier.colour = "red", outlier.shape = 16, outlier.size = 3) + 
  labs(title = "Box Plot of Age (Years)", y = "Age (Years)", x = "") + 
  theme_minimal()

# Create Boxplot for Total Length

pbox_lngth <- ggplot(possums, aes(x = "", y = totlngth)) + 
  geom_boxplot(fill = "lightgreen", outlier.colour = "red", outlier.shape = 16, outlier.size = 3) + 
  labs(title = "Box Plot of Total Length (mm)", y = "Total Length (mm)", x = "") + 
  theme_minimal()

```

```{r format-boxplot1, include=F}

ggsave("boxplot_age.png", plot = pbox_age,   width = 3, height = 4)
ggsave("pbox_lngth.png",  plot = pbox_lngth, width = 3, height = 4)

pboxes <- "
\\begin{figure}[htbp]
    \\centering
    \\makebox[0.65\\textwidth]{  % Adjust overall width
  
        \\begin{minipage}[t]{0.35\\textwidth}
            \\centering
            \\includegraphics[width=\\textwidth]{boxplot_age.png}   \
            \\caption{Age}
        \\end{minipage}
        \\hspace{10pt}  % Adjust horizontal spacing
        \\begin{minipage}[t]{0.35\\textwidth}
            \\centering
            \\includegraphics[width=\\textwidth]{pbox_lngth.png}
            \\caption{Total Length}
        \\end{minipage}
    }
\\end{figure}
"

```

```{r , eval=T}
knitr::asis_output(pboxes)
```


Outliers are present, particularly possums older than 5 years, which will require further examination.
"Figure 2: Box plots illustrating the presence of outliers in age and total length").
The data is raw and unprocessed. Inconsistencies and/or these outliers may be affecting the results. Additional Data cleaning and Analysis is required. As this is only one predictor. Others win need to be explored to build a model that will confidently predict age. 
\newpage 

## 2. Data Preparation 

Histograms and density plots illustrate the spread and shape of each variable. Features such as belly girth and skull width appear to follow a normal distribution, while ear conch length and foot length exhibit bimodal characteristics. The age distribution is right-skewed, indicating that transformation or non-linear modelling approaches may be required.

The presence of extreme values in variables such as total length and tail length suggests that scaling or outlier treatment may be necessary to ensure the stability of regression models.


### 2a. Dropping Unnecessary Columns
Two columns (**case**, **Pop**) were dropped as instructed. **case** was a numerical reference that is not needed in our model; **Pop** was redundant with **site**. 

### 2b. and 2c. Convert Categorical Columns

The categorical data (**sex**, **site**) were changed to an appropriate format as
instructed: **sex** was converted to binary (`female = 1, male = 0`). 
**site** was One-hot encoded and the column for factor 7 was dropped to avoid 
multicollinearity. 

Imputation of Missing Values

Predictive Mean Matching (PMM) via the mice package was chosen for imputing missing values in the dataset. PMM  preserves the original distribution and variability of the dataset by imputing missing values from observed values within the data, rather than introducing values. 


```{r possums-convert1 , eval=T}
set.seed(82171165) 

#  drop case - as this is just a numeric row index
#  drop Pop - it is redundant as we have site. 
#
possums_0 <- subset(possums, select = -c(case, Pop))           # drop case and Pop

#  impute with predictive mean matching finds the closest observed values 
#  in the dataset and randomly selects one to impute the missing value.
#
possums_0 <- mice(possums_0, m=1, method="pmm") |> complete()  # impute

# One-hot encode site: Convert site  into six binary variables (site1 to  site6). 
# site7  is not needed due to the "dummy variable trap".    
#
possums_0$site       <- as.factor(possums_0$site)                       # factor 
ps_dummies           <- model.matrix(~ site - 1, data = possums_0)      # get 7 site columns
psite_7              <- levels(possums_0$site)[7]                       # get factor 7
pcols_2_keep         <- colnames(ps_dummies) != paste0("site", psite_7) # boolean arguments
ps_dummies           <- ps_dummies[, pcols_2_keep]              # remove site7
colnames(ps_dummies) <- paste0("site", levels(possums_0$site)[-7])      # add names
possums_1            <- cbind(possums_0, ps_dummies)                    # combine with dummies
possums_1$site       <- NULL    # remove categorical              

# mutate sex to numberic where female = 1
#
possums_1$sex <- as.numeric(possums_0$sex == "f")            #  true if female

# relocate age to last for analysis 
#
possums_1       <- possums_1 |> relocate(age, .after = last_col()) 
psite_names     <- grep("^site", names(possums_1), value = TRUE)
pdummy_names    <- c(psite_names, "sex")
pdummies        <- possums_1 |> select(pdummy_names)
pnumerics       <- possums_1 |> select(-all_of(pdummy_names))
pnumeric_names  <- pnumerics |> names()
```
\newpage

```{r format-comparison , include=F}
new_colnames <- c( # from assignment
  "sex (female=1)", "head length", "skull length", "body length", 
  "tail length", "foot length", "ear conch length", "eye size", 
  "chest girth", "belly girth", "site1", "site2", "site3", "site4", 
  "site5", "site6", "age (years)"
)

# from image 
possums_1_display <- possums_1
colnames(possums_1_display) <- new_colnames

possums_1_display <- possums_1_display %>%
  rename(
    Cambarville                = site1,
    Bellbird                   = site2,
    `Whian Whian State Forest` = site3,
    `Byrangery Reserve`        = site4,
    `Conondale Ranges`         = site5,
    `Bulburin State Forest`    = site6
  )


# Check new column names
colnames(possums_1_display)


# Create the flextable
pskim_ft1 <- skim_flextable(possums_1_display,2.0)

# Save as an image
save_as_image(pskim_ft1, path = "pskim_ft1.png")
save_as_image(pskim_ft,  path = "pskim_ft.png")
file.exists("pskim_ft.png")
file.exists("pskim_ft1.png")
pcompare_tables <- "
\\begin{figure}[htbp]
    \\centering
    \\begin{minipage}[t]{0.45\\textwidth}
        \\centering
        \\includegraphics[height=9cm]{pskim_ft.png}
        \\captionof{figure}{\\texttt{possums.csv}}
    \\end{minipage}
    \\hfill
    \\begin{minipage}[t]{0.45\\textwidth}
        \\centering
        \\includegraphics[height=9cm]{pskim_ft1.png}
        \\captionof{figure}{\\texttt{possums\\_1}}
    \\end{minipage}
\\end{figure}
"

```


```{r print-tables, eval=T}
knitr::asis_output(pcompare_tables)

```

We begin the Exploratory Data Analysis on the cleaned dataset. This is to better understand the distribution and characteristics of its features. The table below is the key summary statistics, and includes the mean, median, minimum, maximum, and interquartile range (IQR) for each variable. 

```{r possum-summary-stats, eval=T}
# Compute summary statistics for all numeric features
possum_summary <- possums_1  |>
  select(where(is.numeric)) |>
  summarise(
    across(
      everything(), 
      .fns = list(
        Mean = \(x) mean(x, na.rm = TRUE), 
        Median = \(x) median(x, na.rm = TRUE), 
        Min = \(x) min(x, na.rm = TRUE), 
        Max = \(x) max(x, na.rm = TRUE), 
        IQR = \(x) IQR(x, na.rm = TRUE)
      )
    )
  )

```


```{r format-possum-summary-table, include=F}

possum_summary    <- possum_summary |> pivot_longer(cols      = everything(),
                                                 names_to  = c("Variable", ".value"),
                                                 names_sep = "_")
possum_summary    <- mutate(possum_summary,Mean = round(Mean, 2))
possum_summary_ft <- flextable(possum_summary) |> #  flextable to display
  set_header_labels(
    Variable = "Feature",
    Mean     = "Mean",
    Median   = "Median",
    Min      = "Min",
    Max      = "Max",
    IQR      = "Interquartile Range"
  ) |>
  theme_vanilla() |>
  width(j = 1, width = 1) |>  # Manually set column widths
  width(j = 2:6, width = 1)   # Adjust other columns

```


```{r possum-summary-table2, eval=T}
possum_summary_ft
```

Histograms will now allow us to examine the distribution of numerical features, identifying skewness, outliers, and potential transformations needed for improved model performance.Transformations may be necessary to improve normality and stabilise variance.




```{r possum-histograms, eval=T}

# Select only numeric features excluding one-hot encoded variables and sex
possums_long_col <- pivot_longer(pnumerics,
                                 cols = all_of(pnumeric_names), 
                                 names_to = "Variable", 
                                 values_to = "Value") |> drop_na(Value) 

# Create histogram and density plots
#
phistograms <- ggplot(possums_long_col, aes(x = Value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", linewidth = 1) +  # Overlay density curve
  facet_wrap(~ Variable, scales = "free", ncol = 3) +  # Facet by variable
  theme_minimal() +
  labs(title = "Histograms and Density Plots of Numeric Features (Excluding One-Hot Variables and Sex)",
       x = "Value",
       y = "Density")

# Print plot
phistograms
```
## Exploratory Data Analysis (EDA)

The dataset has been processed by handling missing values, encoding categorical variables, and standardising features, we now explore the numerical distributions. The goal is to identify potential transformations required to normalise skewed distributions and detect multicollinearity among predictors.

Histograms and density plots show the spread and shape of each variable. Features such as belly girth and skull width appear to follow a normal distribution, while ear conch length and foot length exhibit bimodal characteristics. The age distribution is right-skewed, indicating that transformation or non-linear modelling approaches may be required.

The presence of extreme values in variables such as total length and tail length suggests that scaling or outlier treatment may be necessary to ensure the stability of regression models.
 
 
We identify the most important predictors using Ridge Regression Before training the model. This method penalises large coefficients, reducing multicollinearity and improving generalisability. Top features selected will form the basis for our predictive model.

It may be important to determine whether the correlations differ depending on sex. I  filtering the dataset into subsets for males and females separately, compute distinct correlation matrices for each group to see if this approach allows us to identify whether the strength and direction of relationships between variables vary based on sex. This could influence the final model selection and interpretation.

We stratified by sex, however, the correlation analysis itself does not incorporate sex as a predictor. This ensuring that only numerical variables are examined for dependencies.

Once the correlation matrix is created for each subset, it is converted into a long format. This transformation simplifies the process of identifying highly correlated predictor pairs and allows for easier filtering and visualisation. While the long-format table itself does not explicitly track which subset (male, female, or full dataset) the correlations were derived from, maintaining separate outputs for each ensures clarity in analysis.

This approach addresses that we can compare correlations across sexes while keeping the analysis streamlined and focused on numerical relationships. It also helps in detecting potential multicollinearity issues within each subset, which is crucial for building a robust predictive model.

The correlation matrix is visualised using a heatmap to highlight potential multicollinearity, where strong correlations (above 0.8) may indicate redundancy among predictors.
 


```{r possum-correlation2, eval=T}
# Select only numeric features excluding one-hot variables and sex

p_matrix1 <- cor(pnumerics, use = "pairwise.complete.obs")
pcor_long <- as.data.frame(p_matrix1) |>
  rownames_to_column(var = "Variable1") |>
  pivot_longer(cols = -Variable1,
               names_to = "Variable2",
               values_to = "Correlation")

# Identify highly correlated predictor pairs (|correlation| > 0.8)
pcor_high <- filter(pcor_long, abs(Correlation) > 0.8 & Variable1 != Variable2)

pto_keep <- filter(pcor_long, Variable1 >= Variable2) |> # Keep lower triangle 
  anti_join(pcor_high, by = c("Variable1", "Variable2")) # remove high correlations


if (nrow(pto_keep) > 0) { # if correlations remain after filtering

  p_correlation_heatmap <- ggplot(pto_keep,             # Create heatmap
                                  aes(x = Variable1, 
                                      y = Variable2, 
                                      fill = Correlation)) +
    geom_tile(color = "white") +
    geom_text(aes(label = round(Correlation, 2)), color = "black", size = 3) +
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
    theme_minimal() +
    labs(title = "Lower Triangle Correlation Matrix\nof All Data (Ignoring Sex)", 
         fill = "Correlation") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save heatmap
  ggsave("p_correlation_heatmap.png", 
         p_correlation_heatmap,
         width = 6, height = 4, dpi = 300, path = getwd())
  pformat_heatmap <- ""
  if (!file.exists("p_correlation_heatmap.png")) { 
    cat("No heatmap file created.") }  

  } else {
  cat("No correlations remain after filtering high-correlation pairs.")
  if (file.exists("p_correlation_heatmap.png")) { file.remove("p_correlation_heatmap.png") }
}
```

```{r , include=F}
    pformat_heatmap <- "\\begin{figure}[H]\n  \\centering\n    
    \\begin{minipage}{0.7\\textwidth}\n      \\centering\n
    \\includegraphics[width=\\textwidth]{p_correlation_heatmap.png}\n
    \\caption{asdf}\n     \\end{minipage}\n\\end{figure}"
```

```{r}
 knitr::asis_output(pformat_heatmap)

```
Scatter Plots Analysis

Tese Scatter plots show the relationships between the age of possums (dependent variable) and various numerical predictors. Each plot provides the strength of the relationships:

Predictors  skull width (skullw), and total length (totlngth) exhibit weak positive correlations, and a slight tendency for age to increase as these features grow larger.

Belly girth (belly), chest girth (chest), and tail length (taill) show minimal correlation, showing limited predictive power.

Head length (hdlngth) and ear conch length (earconch) reveal  variability and ambiguous relationships,  suggesting a nonlinear interactions or requiring further transformation.

The scatter plots confirm considerable variability and only modest linear associations between age and individual predictors. These  suggest that a more complex, multivariate regression model, such as Ridge Regression, is necessary to capture the collective predictive power of multiple variables.

```{r possum-scatterplots, eval=T}


pscatter_lcol <- pivot_longer(pnumerics,
                             cols = all_of(pnumeric_names),
                             names_to = "Predictor",
                             values_to = "Value") |>  
  mutate(age = rep(possums_1$age,
                   length(pnumeric_names))) #|>  # Restore 'age' column


possums_long_scatter <- possums_1 |>
  pivot_longer(cols = all_of(pnumeric_names), names_to = "Predictor", values_to = "Value") |>  
  mutate(age = rep(possums_1$age, length(pnumeric_names))) |>  # Restore 'age' column
  drop_na(Value, age)  # Remove missing values

# Confirm 'age' exists
print(colnames(pscatter_lcol))  # Debugging step
print(head(pscatter_lcol))  # Debugging step

# Create scatterplot with facets for different predictors
p_scatterplots <- ggplot(pscatter_lcol, aes(x = Value, y = age)) +
  geom_point(alpha = 0.6) +  # Scatter points
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1) +  # Regression line
  facet_wrap(~ Predictor, scales = "free", ncol = 3) +  # Facet by predictor
  labs(title = "Scatterplots of Age vs Numeric Predictors",
       x = "Predictor Value",
       y = "Age (Years)") +
  theme_minimal()

# Print plot
p_scatterplots

```





### 2d. Data Splitting for Training, Testing, and Validation

The dataset is split with a focus on stratification with 80% Training 
(**possum_2**), 10% Test(**pTestDf**), used to evaluate models, and 
10% Validation (**pValidateDf**), used for final model selection and assessment

```{r possum-data-splitting , eval=T}

# data-splitting is performed before cleaning predictors 
# to simulate real-world events. 
# 
pTrainIdx <- createDataPartition(possums_1$age, p = 0.8, list = FALSE)
possums_2 <- possums_1[pTrainIdx, ]

# pTestDf     is the test possum data       (with stratification)
# pValidateDf is the validation possum data (with stratification) 
#
pTempDf     <- possums_1[-pTrainIdx, ]  #not train
pTestIdx    <- createDataPartition(pTempDf$age, p = 0.5, list = FALSE) 
pTestDf     <- pTempDf[pTestIdx, ]   
pValidateDf <- pTempDf[-pTestIdx, ]

```

```{r format-split, include=F}
total_rows <- nrow(possums_1)

#  dataframe
#
psplit_df <- data.frame(
  Dataset = c("possums_2", "pTestDf", "pValidateDf"),
  `pctExpected` = c(80, 10, 10),
  `xExpected`   = c(total_rows * 0.8, total_rows * 0.1, total_rows * 0.1),
  `xActual`     = c(nrow(possums_2), nrow(pTestDf), nrow(pValidateDf))  # Actual values from your dataset
   )

# flextable
#
psplit_ft <- flextable(psplit_df) |> 
  set_header_labels(
     Dataset      = "Dataset",
    `pctExpected` = "Percentage",
    `xExpected`   = "Calculate Rows",
    `xActual`     = "Actual Rows"
  ) |> 
  autofit() |>  # fit the content
  width(j = 1, width = .8) |>           # Dataset 
  width(j = 2:4, width = 0.8) |>        # other columns
  set_table_properties(width = 0.3) |>  #  overall  width
  autofit()  # fit the widths setting
```

While stratification helps maintain representative samples, the constraints of whole-number rows and maintaining class balance mean that the exact number of rows in each split may differ slightly from expected percentages. This explains why possums_2, pTestDf, and pValidateDf did not match the precise 80-10-10 split but were close enough to maintain the stratified structure.
\newpage 

```{r print-split, eval=T}

print(psplit_ft)

```


## Feature Selection and Model Training 
"Once the most relevant predictors are identified, the dataset has been divided into training, testing, and validation subsets to ensure robust model evaluation. Ridge Regression is trained using cross-validation to optimise performance."

Feature Selection: Ridge Regression
Given the presence of multicollinearity, we employ Ridge Regression, a penalised regression method that shrinks large coefficients, thereby improving model generalisability. Unlike standard linear regression, Ridge reduces the impact of correlated variables, preventing overfitting.

The Ridge Regression loss function is:

```{r }



ploss_equation = "
\\[
\\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2
\\]
\\newline

\\textbf{where:}
\\begin{itemize}
  \\item \\( y_i \\) is the dependent variable (age),
  \\item \\( X_i \\) represents the predictor variables,
  \\item \\( \\beta_j \\) are the regression coefficients,
  \\item \\( \\lambda \\) is the penalty parameter.
\\end{itemize}
"

#knitr::knit_print(ploss_equation, output_format = "latex")
 knitr::asis_output(ploss_equation)
```
The optimal lambda value is determined via cross-validation, ensuring that the best trade-off between model complexity and predictive accuracy is achieved.


```{r ltx-rr-explanation, echo=FALSE}
textf <- "
### Why Ridge Regression?

Ridge Regression was chosen due to the presence of **multicollinearity** among the predictor variables. Multicollinearity occurs when predictors are highly correlated, causing instability in ordinary least squares regression estimates, resulting in large variances for estimated coefficients.

Ridge Regression addresses this issue by applying an \\(L_2\\)-penalty to the regression coefficients, defined by the loss function:

\\[
\\text{Loss function} = \\sum_{i=1}^{n}(y_i - X_i\\beta)^2 + \\lambda \\sum_{j=1}^{p}\\beta_j^2
\\]

This penalty shrinks larger coefficients towards zero, stabilising their estimates. Ridge Regression thus reduces variance, improves predictive accuracy, and enhances generalisability. The optimal penalty parameter (\\(\\lambda\\)) is determined using cross-validation, ensuring the model achieves an effective balance between complexity and predictive performance.
"

knitr::asis_output(textf)
```

```{r ridge-regression, eval=T}
#
#
pridge_x <- as.matrix(possums_2 %>% select(-age))  # Exclude age 
pridge_y <- possums_2$age                          # Potential predictors
pridge_cv   <- cv.glmnet(pridge_x, pridge_y, alpha = 0, nfolds = 10)   # Cross-Validation
plambda_min <- pridge_cv$lambda.min                                    # Best lambda

# Fit final Ridge model
pridge_model <- glmnet(pridge_x, pridge_y, alpha = 0, lambda = plambda_min) 
pridge_coeff <- coef(pridge_model)  

# Predict on validation set
pridge_x_val <- as.matrix(pValidateDf %>% select(-age))
pridge_pred  <- predict(pridge_model, newx = pridge_x_val) 

#  evaluation metrics
pridge_mse   <- mean((pValidateDf$age - pridge_pred)^2)   
pridge_rmse  <- sqrt(pridge_mse)  
pridge_mae   <- mean(abs(pValidateDf$age - pridge_pred))  
pridge_rse   <- summary(lm(age ~ ., data = possums_2))$sigma  
pridge_adjR2 <- summary(lm(age ~ ., data = possums_2))$adj.r.squared  
pridge_aic   <- AIC(lm(age ~ ., data = possums_2))  

#  Ridge Regression coefficients to dataframe
pridge_coeff_df <- as.data.frame(as.matrix(pridge_coeff))
colnames(pridge_coeff_df) <- "Coefficient"
pridge_coeff_df$Predictor <- rownames(pridge_coeff_df)
rownames(pridge_coeff_df) <- NULL

# Sort by importance (absolute value of coefficients) & keep top 10
pridge_coeff_df <- pridge_coeff_df %>%
  arrange(desc(abs(Coefficient))) %>%
  filter(Predictor != "(Intercept)") %>%
  head(10)


```

## Model Evaluation
```{r ridge-model-evaluation, eval=T}

# Print Ridge Regression evaluation metrics
#
print(paste("Best Lambda for Ridge:", plambda_min))
print(paste("Ridge Regression MSE:", pridge_mse))
print(paste("Ridge Regression RMSE:", pridge_rmse))
print(paste("Ridge Regression MAE:", pridge_mae))
print(paste("Ridge Regression Residual Standard Error:", pridge_rse))
print(paste("Ridge Regression Adjusted R²:", pridge_adjR2))
print(paste("Ridge Regression AIC:", pridge_aic))

# Print the top 10 most important predictors based on Ridge coefficients
print("Top 10 Important Predictors (Ridge Regression):")
print(pridge_coeff_df)

```



```{r ridge-feature-selection, eval=T}

# Convert Ridge Regression coefficients to a dataframe
#
pridge_coeff_df <- as.data.frame(as.matrix(pridge_coeff))
colnames(pridge_coeff_df) <- "Coefficient"
pridge_coeff_df$Predictor <- rownames(pridge_coeff_df)
rownames(pridge_coeff_df) <- NULL

# Sort predictors by absolute coefficient values (most important first)
pridge_coeff_df <- pridge_coeff_df %>%
  arrange(desc(abs(Coefficient)))

# Remove the intercept term
pridge_coeff_df <- pridge_coeff_df %>% filter(Predictor != "(Intercept)")

# there are 16 possible features
#
num_features <- 16   
top_predictors <- pridge_coeff_df %>% head(num_features) %>% pull(Predictor)

# Construct the final model formula using selected features
ridge_selected_formula <- as.formula(paste("age ~", paste(top_predictors, collapse = " + ")))

# Fit the final linear model using Ridge-selected predictors
plm <- lm(ridge_selected_formula, data = possums_2)

# Print selected predictors
print(paste("Selected Predictors for Final Model:", paste(top_predictors, collapse = ", ")))


```



```{r possum-model-selection,     eval=T}

# Define all possible predictor combinations
#
#psite_cols <- grep("^site", names(possums_2), value = TRUE)

# Exclude age, sex, and one-hot encoded site variables
#

predictors  <- names(possums_2)
predictors  <- names(possums_2)[!names(possums_2) %in% c("age", "sex", pdummy_names)]


# Perform best subset selection
#

possum_models <- regsubsets(age ~ ., data = possums_2, nvmax = 256)  # exhaustive but greedy


# Evaluate models on validation set
#

pmodel_summary     <- summary(possum_models)

# Select the best model based on BIC
#

pmodel_idx <- which.min(pmodel_summary$bic)  
pmodel_predictors <- names(which(pmodel_summary$which[pmodel_idx, ] == TRUE))[-1]

# Construct formula for best model
#

pmodel_formula <- as.formula(paste("age ~", paste(pmodel_predictors, collapse = " + ")))

# Fit the best model
plm <- lm(pmodel_formula, data = possums_2)

# Predictions on validation set
preds <- predict(plm, newdata = pValidateDf)

# Compute Additional Metrics
pMSE_validate  <- mean((pValidateDf$age - preds)^2)  # MSE
pRMSE_validate <- sqrt(pMSE_validate)  # RMSE
pMAE_validate  <- mae(pValidateDf$age, preds)  # MAE
pRSE           <- summary(plm)$sigma  # Residual Standard Error
pAdjR2         <- summary(plm)$adj.r.squared  # Adjusted R²
pAIC           <- AIC(plm)  # AIC Score

print(pMSE_validate)

```

```{r ,results='asis', echo=FALSE}
model_explanation <- "
\\subsection*{Model Explanation}

\\subsubsection*{Model Form}

The final linear regression model selected via Ridge Regression has the following general form:

\\[
age = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon
\\]

\\textbf{where:}
\\begin{itemize}
    \\item \\( age \\) is the dependent variable representing the age of possums.
    \\item \\( \\beta_0 \\) is the intercept, indicating the predicted age when all predictors are zero.
    \\item \\( \\beta_1, \\beta_2, \\dots, \\beta_p \\) are regression coefficients for each predictor variable selected by Ridge Regression.
    \\item \\( X_1, X_2, \\dots, X_p \\) are the predictor variables identified by Ridge Regression as significant for predicting age.
    \\item \\( \\epsilon \\) represents the residual (error term) and is assumed to follow a normal distribution \\( \\epsilon \\sim N(0, \\sigma^2) \\).
\\end{itemize}

Ridge Regression shrinks coefficients towards zero, controlling model complexity and reducing multicollinearity. The penalty parameter \\( \\lambda \\) was optimised via cross-validation, providing a balance between predictive accuracy and generalisability.

Below is the explicitly defined model, showing the estimated regression coefficients from the final Ridge-selected linear regression model:
"

knitr::asis_output(model_explanation)

coefficients_df <- summary(plm)$coefficients

# Start building the equation string
equation <- "\\begin{equation}\n\\text{age} = "
equation <- paste0(equation, round(coefficients_df[1, 1], 3))

# Append each predictor term
for (i in 2:nrow(coefficients_df)) {
  coef <- round(coefficients_df[i, 1], 3)
  sign <- ifelse(coef >= 0, " + ", " - ")
  predictor <- colnames(possums_2)[i - 1]

  equation <- paste0(equation, sign, abs(coef), " \\times \\text{", predictor, "}")
}

# Close the equation
equation <- paste0(equation, "\n\\end{equation}\n")

# Output the equation with asis_output
knitr::asis_output(equation)
```


```{r possum-model-selection2, results='asis', eval=F}
# Print Model Performance Metrics
metrics_df <- data.frame(
  Metric = c("MSE", "RMSE", "MAE", "Residual Std Error", "Adjusted R2", "AIC"),
  Value = unlist(c(pMSE_validate, pRMSE_validate, pMAE_validate, pRSE, pAdjR2, pAIC))
)

print(metrics_df)

# Print Model Coefficients
print("Model Coefficients:")
print(summary(plm)$coefficients)

# Convert subset selection results into a DataFrame
summary_mat <- as.data.frame(pmodel_summary$which)
colnames(summary_mat)[1] <- "Intercept"

# Replace TRUE/FALSE with symbols for better readability
summary_mat[summary_mat == TRUE] <- "T"
summary_mat[summary_mat == FALSE] <- ""

# Convert to flextable for better visualization
summary_ft <- flextable(summary_mat) |>
  set_table_properties(width = 0.9, layout = "autofit") |>
  theme_vanilla() |>
  bold(j = 1, bold = TRUE) |>
  align(align = "center", part = "all") |>
  border_outer(part = "all", border = officer::fp_border(color = "black", width = 1)) |>
  border_inner_h(border = officer::fp_border(color = "black", width = 0.5)) |>
  border_inner_v(border = officer::fp_border(color = "black", width = 0.5)) |>
  rotate(j = 1:ncol(summary_mat), rotation = "btlr", part = "header")

# Print table
summary_ft

```

To ensure our final Ridge Regression model is robust, we must validate several key regression assumptions. Specifically, we will:

- **Check Linearity & Homoscedasticity**: Residuals versus fitted values should show no obvious pattern, indicating constant variance.
- **Assess Normality**: Residuals should approximately follow a normal distribution, verified using a QQ plot.
- **Inspect Influential Observations**: Points that disproportionately influence the regression results (leverage points) should be examined using Cook’s distance.

Our final model, trained using Ridge Regression, demonstrates  predictive accuracy. The diagnostic plots reveal minor deviations from the assumptions of normality and constant variance, these deviations are not substantial enough to undermine the reliability of the model. No extreme violations of regression assumptions were observed. Future improvements might include exploring non-linear transformations or alternative feature selection methods to enhance model performance.


```{r residual-analysis, eval=T}
# Compute residuals from the current linear model
residuals_df <- data.frame(
  Fitted = fitted(plm),
  Residuals = residuals(plm),
  Standardized_Residuals = rstandard(plm),
  Leverage = hatvalues(plm),
  CookD = cooks.distance(plm)
)

# 1 Residuals vs. Fitted Plot (Check Homoscedasticity)
p_residuals_vs_fitted <- ggplot(residuals_df, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

# 2 QQ Plot of Residuals (Check Normality)
p_qqplot <- ggplot(residuals_df, aes(sample = Standardized_Residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "QQ Plot of Residuals", x = "Theoretical Quantiles", y = "Standardised Residuals") +
  theme_minimal()

# 3 Residuals vs. Leverage Plot (Detect Influential Points)
p_leverage <- ggplot(residuals_df, aes(x = Leverage, y = Standardized_Residuals, size = CookD)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_hline(yintercept = c(-2, 2), linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. Leverage", x = "Leverage", y = "Standardised Residuals", size = "Cook's Distance") +
  theme_minimal()
```


```{r residual-analysis1, eval=T}
# Print plots
print(p_residuals_vs_fitted)
```
 Residuals vs. Fitted Values Plot:

The residuals should be randomly scattered around zero without any clear pattern.
The plot shows some heteroscedasticity (variance of residuals appears to increase for larger fitted values).
There is a possible funnel shape, indicating that the variance may not be constant, violating homoscedasticity.
There are no extreme outliers, but some points seem to be slightly away from the main cluster.


```{r residual-analysis11, eval=T}
print(p_qqplot)
```

 QQ Plot of Residuals:

The QQ plot assesses normality of residuals.
The residuals mostly follow the theoretical quantiles, but some points deviate in the upper and lower extremes.
This suggests some non-normality, potentially indicating skewness or heavier tails than expected in a normal distribution.
```{r residual-analysis1111, eval=T}
print(p_leverage)
```
 Residuals vs. Leverage Plot:

This plot helps identify influential points using leverage and Cook’s Distance.
Most points have low leverage, meaning they don’t disproportionately influence the regression model.
A few points have higher leverage, but none seem to have extreme influence (Cook’s Distance > 0.5 is usually considered problematic).
The majority of standardised residuals fall within the acceptable range (-2 to 2), but some approach these limits.

\newpage 

```{r possum-model-selection21, eval=F}
# Print the formatted table
#summary_ft
```

Summary of Issues:
Residual analysis reveals mild heteroscedasticity, suggesting that variance is not entirely constant across fitted values. The QQ plot indicates minor departures from normality. No extreme influential points were detected, indicating a model robustness.

# ---------------------------
\newpage 

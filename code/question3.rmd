---
output:
  pdf_document: default
  html_document: default
---


# ---------------------------
```{r echo=T}
chunk_options_df <- data.frame(
  Option = c("echo=TRUE (default)", "echo=FALSE", "eval=FALSE", "include=FALSE", 'results="hide"'),
  Code_Displayed = c("Yes", "No", "Yes", "No", "Yes"),
  Code_Executed = c("Yes", "Yes", "No", "Yes", "Yes"),
  Output_Shown = c("Yes", "Yes", "No", "No", "No")
)

# Convert to flextable
chunk_options_ft <- flextable(chunk_options_df) |>
  set_header_labels(
    Option = "Option",
    Code_Displayed = "Code Displayed?",
    Code_Executed = "Code Executed?",
    Output_Shown = "Output Shown?"
  ) |>
  theme_vanilla() |> 
  autofit()
chunk_options_ft
```




## Description

```{r possum-map, echo=FALSE, out.width="70%", fig.align='center'}
  # Load data-set and visualise
  knitr::include_graphics("../images/possum_age_plot.png")

```


##3. Feature Selection## 4. Model Training## 5. Model Evaluation## 6. Validation on Test Set## 7. Interpretation and Further Exploration

\newpage 
## 1. Data Loading

The data was loaded via a common function  load_datasets() ` used to load all data from  ../data/dataset.zip . See Appendix for the description. The data used for these questions is as follows: 
```{r format-possums,   eval=F}
pskim_ft = skim_flextable(possums)
pskim_ft
```

Plotting age vs Total Length (totlngth)

```{r possum-scatterplot1, eval=F}
# visualise age vs totlnght
# assuming length is in mm and age is in years
#
pPlot_age_v_lngth <- ggplot(possums, aes(x = totlngth, y = age)) +
  geom_point(color = "blue", alpha = 0.6) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
  # ggtitle("Age vs. Total Length") +
  xlim(73, 96) +  # Set x-axis limits
  xlab("Total Length (mm)") +
  ylab("Age (years)") +
  theme_minimal()
```

```{r , eval=F}
ggsave("possum-scatter-plot.png", pPlot_age_v_lngth, width = 6, height = 4, dpi = 300)  # Adjust width & height

pPlot_age_v_lngth <- "
\\begin{figure}[H]
    \\centering
    \\begin{minipage}{0.5\\textwidth}  % Set to 50% of page width
        \\centering
        \\includegraphics[width=\\textwidth]{possum-scatter-plot.png}
        \\caption{Age vs. Total Length}
    \\end{minipage}
\\end{figure}
"

```
\newpage
An initial scatter plot shows  the raw data directly from the CSV file. It is a plot of age (years) vs total body length (mm) of the possums.

```{r possum-scatterplot2, eval=F}
knitr::asis_output(pPlot_age_v_lngth)
```

There is a **weak positive correlation**  seen by the regression line. This suggests a weak relationship that as total length increases, the age  increases. There is a **high degree of variability** that goes against the regression line -  some younger possums have large total lengths, and some older ones have shorter total lengths.

Additionally, the data points are widely spread, particularly at higher total lengths, suggesting that total length alone is not be a strong predictor of age. There is a high density of points is between 80–95 mm in total length. There is a high density of points between 1–6 years in age. This indicates that most possums fall within this range. 

\newpage
```{r possum-boxplots1 , eval=F}
pbox_age <- ggplot(possums, aes(x = "", y = age)) + 
  geom_boxplot(fill = "lightblue", outlier.colour = "red", outlier.shape = 16, outlier.size = 3) + 
  labs(title = "Box Plot of Age (Years)", y = "Age (Years)", x = "") + 
  theme_minimal()

# Create Boxplot for Total Length

pbox_lngth <- ggplot(possums, aes(x = "", y = totlngth)) + 
  geom_boxplot(fill = "lightgreen", outlier.colour = "red", outlier.shape = 16, outlier.size = 3) + 
  labs(title = "Box Plot of Total Length (mm)", y = "Total Length (mm)", x = "") + 
  theme_minimal()


```

```{r boxplot1-print, eval=F}

ggsave("boxplot_age.png", plot = pbox_age,   width = 3, height = 4)
ggsave("pbox_lngth.png",  plot = pbox_lngth, width = 3, height = 4)

pboxes <- paste("
\\begin{figure}[htbp]
    \\centering
    \\makebox[0.65\\textwidth]{  % Adjust overall width
  
        \\begin{minipage}[t]{0.30\\textwidth}
            \\centering
            \\includegraphics[width=\\textwidth]{boxplot_age.png}   \
            \\caption{Age}
        \\end{minipage}
        \\hspace{10pt}  % Adjust horizontal spacing
        \\begin{minipage}[t]{0.30\\textwidth}
            \\centering
            \\includegraphics[width=\\textwidth]{pbox_lngth.png}
            \\caption{Total Length}
        \\end{minipage}
    }
\\end{figure}
", sep = "\n")

```

```{r , eval=F}
knitr::asis_output(pboxes)
```


Outliers are present, particularly possums older than 5 years, which will require further examination.

The data is raw and unprocessed. Inconsistencies and/or these outliers may be affecting the results. Additional Data cleaning and Analysis is required. As this is only one predictor. Others win need to be explored to build a model that will confidently predict age. 




### 2a. Dropping Unnecessary Columns
Two columns (**case**, **Pop**) were dropped as instructed. **case** was a numerical reference that is not needed in our model; **Pop** was redundant with **site**. 

### 2b. and 2c. Convert Categorical Columns

The categorical data (**sex**, **site**) were changed to an appropriate format as
instructed: **sex** was converted to binary (`female = 1, male = 0`). 
**site** was One-hot encoded and the column for factor 7 was dropped to avoid 
multicollinearity. 

In preperation for splitting the data and ensuring stratification, missing data in age is imputing with `mice(method = "pmm")` which provide a predictive mean matching method. 
We imputed the data rather than removed it due to the small number of data rows and the large number of predictors. In particular, **age** could not be left with `NA`.


```{r possums-convert1 , eval=F}
set.seed(82171165) 

#  drop case - as this is just a numeric row index
#  drop Pop - it is redundant as we have site. 
#
possums_0 <- subset(possums, select = -c(case, Pop))           # drop case and Pop

#  impute with predictive mean matching finds the closest observed values 
#  in the dataset and randomly selects one to impute the missing value.
#
possums_0 <- mice(possums_0, m=1, method="pmm") |> complete()  # impute

# One-hot encode site: Convert site  into six binary variables (site1 to  site6). 
# site7  is not needed due to the "dummy variable trap".    
#
possums_0$site       <- as.factor(possums_0$site)                       # factor 
ps_dummies           <- model.matrix(~ site - 1, data = possums_0)      # get 7 site columns
psite_7              <- levels(possums_0$site)[7]                       # get factor 7
pcols_2_keep         <- colnames(ps_dummies) != paste0("site", psite_7) # boolean arguments
ps_dummies           <- ps_dummies[, pcols_2_keep]              # remove site7
colnames(ps_dummies) <- paste0("site", levels(possums_0$site)[-7])      # add names
possums_1            <- cbind(possums_0, ps_dummies)                    # combine with dummies
possums_1$site       <- NULL    # remove categorical              

# mutate sex to numberic where female = 1
#
possums_1$sex <- as.numeric(possums_0$sex == "f")            #  true if female

# relocate age to last for analysis 
#
possums_1 <- possums_1 |> relocate(age, .after = last_col()) 

```
\newpage

```{r format_comparison , eval=F}


new_colnames <- c( # from assignment
  "sex (female=1)", "head length", "skull length", "body length", 
  "tail length", "foot length", "ear conch length", "eye size", 
  "chest girth", "belly girth", "site1", "site2", "site3", "site4", 
  "site5", "site6", "age (years)"
)

# from image 
possums_1_display <- possums_1
colnames(possums_1_display) <- new_colnames

possums_1_display <- possums_1_display %>%
  rename(
    Cambarville                = site1,
    Bellbird                   = site2,
    `Whian Whian State Forest` = site3,
    `Byrangery Reserve`        = site4,
    `Conondale Ranges`         = site5,
    `Bulburin State Forest`    = site6
  )


# Check new column names
colnames(possums_1_display)


# Create the flextable
pskim_ft1 <- skim_flextable(possums_1_display,2.0)

# Save as an image
save_as_image(pskim_ft1, path = "pskim_ft1.png")
save_as_image(pskim_ft,  path = "pskim_ft.png")
file.exists("pskim_ft.png")
file.exists("pskim_ft1.png")
pcompare_tables <- paste("
\\begin{figure}[htbp]
    \\centering
    \\begin{minipage}[t]{0.45\\textwidth}
        \\centering
        \\includegraphics[height=9cm]{pskim_ft.png}
        \\captionof{figure}{\\texttt{possums.csv}}
    \\end{minipage}
    \\hfill
    \\begin{minipage}[t]{0.45\\textwidth}
        \\centering
        \\includegraphics[height=9cm]{pskim_ft1.png}
        \\captionof{figure}{\\texttt{possums\\_1}}
    \\end{minipage}
\\end{figure}
", sep = "\n")

```


```{r print-tables, eval=F}
knitr::asis_output(pcompare_tables)

```


### 2d. Data Splitting for Training, Testing, and Validation

The dataset is split with a focus on stratification with 80% Training 
(**possum_2**), 10% Test(**pTestDf**), used to evaluate models, and 
10% Validation (**pValidateDf**), used for final model selection and assessment

```{r possum-data-splitting , eval=F}

# data-splitting is performed before cleaning predictors 
# to simulate real-world events. 
# 
pTrainIdx <- createDataPartition(possums_1$age, p = 0.8, list = FALSE)
possums_2 <- possums_1[pTrainIdx, ]

# pTestDf     is the test possum data       (with stratification)
# pValidateDf is the validation possum data (with stratification) 
#
pTempDf     <- possums_1[-pTrainIdx, ]  #not train
pTestIdx    <- createDataPartition(pTempDf$age, p = 0.5, list = FALSE) 
pTestDf     <- pTempDf[pTestIdx, ]   
pValidateDf <- pTempDf[-pTestIdx, ]

```

```{r format-split, eval=F}
total_rows <- nrow(possums_1)

#  dataframe
#
psplit_df <- data.frame(
  Dataset = c("possums_2", "pTestDf", "pValidateDf"),
  `pctExpected` = c(80, 10, 10),
  `xExpected`   = c(total_rows * 0.8, total_rows * 0.1, total_rows * 0.1),
  `xActual`     = c(nrow(possums_2), nrow(pTestDf), nrow(pValidateDf))  # Actual values from your dataset
   )

# flextable
#
psplit_ft <- flextable(psplit_df) |> 
  set_header_labels(
     Dataset      = "Dataset",
    `pctExpected` = "Percentage",
    `xExpected`   = "Calculate Rows",
    `xActual`     = "Actual Rows"
  ) |> 
  autofit() |>  # fit the content
  width(j = 1, width = .8) |>           # Dataset 
  width(j = 2:4, width = 0.8) |>        # other columns
  set_table_properties(width = 0.3) |>  #  overall  width
  autofit()  # fit the widths setting

```
\newpage

While stratification helps maintain representative samples, the constraints of whole-number rows and maintaining class balance mean that the exact number of rows in each split may differ slightly from expected percentages. This explains why possums_2, pTestDf, and pValidateDf did not match the precise 80-10-10 split but were close enough to maintain the stratified structure.

```{r print-split, eval=F}
knitr::knit_print(psplit_ft, output_format = "latex")
```





```{r models-evaluation, eval=F}


# Define all possible predictor combinations
#


# Identify dummy cols
psite_cols <- grep("^site", names(possums_2), value = TRUE)

# all predictors excluding age, sex, and  dummies
#
predictors    <- names(possums_2)[!names(possums_2) %in% c("age", "sex", psite_cols)]
predictors_2  <- names(possums_2)
possum_models <- regsubsets(age ~ ., data = possums_2, nvmax = 256)  # Increase nvmax

# Evaluate models on validation set
pmodel_summary <- summary(possum_models)
pmodel_idx <- which.min(pmodel_summary$bic) # Select best model based on BIC (bayesian)
pmodel_predictors <- names(which(pmodel_summary$which[pmodel_idx, ] == TRUE))[-1]  # Extract best predictors

# Construct formula for the best model
pmodel_formula <- as.formula(paste("age ~", paste(pmodel_predictors, collapse = " + ")))

# Fit the best model
plm <- lm(pmodel_formula, data = possums_2)

# Evaluate on validation set
preds <- predict(plm, newdata = pValidateDf)
pMSE_validate <- mean((pValidateDf$age - preds)^2)

# Print MSE
print(pMSE_validate)
 
```


```{r possum-model-selection,     eval=F}

# Define all possible predictor combinations
#
psite_cols <- grep("^site", names(possums_2), value = TRUE)

# Exclude age, sex, and one-hot encoded site variables
#
predictors  <- names(possums_2)[!names(possums_2) %in% c("age", "sex", psite_cols)]
predictors  <- names(possums_2)

# Perform best subset selection
#
possum_models <- regsubsets(age ~ ., data = possums_2, nvmax = 256)  # exhaustive but greedy


# Evaluate models on validation set
#
pmodel_summary     <- summary(possum_models)

# Select the best model based on BIC
pmodel_idx <- which.min(pmodel_summary$bic)  
pmodel_predictors <- names(which(pmodel_summary$which[pmodel_idx, ] == TRUE))[-1]

# Construct formula for best model
pmodel_formula <- as.formula(paste("age ~", paste(pmodel_predictors, collapse = " + ")))

# Fit the best model
plm <- lm(pmodel_formula, data = possums_2)

# Predictions on validation set
preds <- predict(plm, newdata = pValidateDf)

# Compute Additional Metrics
pMSE_validate  <- mean((pValidateDf$age - preds)^2)  # MSE
pRMSE_validate <- sqrt(pMSE_validate)  # RMSE
pMAE_validate  <- mae(pValidateDf$age, preds)  # MAE
pRSE           <- summary(plm)$sigma  # Residual Standard Error
pAdjR2         <- summary(plm)$adj.r.squared  # Adjusted R²
pAIC           <- AIC(plm)  # AIC Score

print(pMSE_validate)

```


```{r possum-model-selection2,  results='asis' , eval=F}
# Print Metrics
metrics_df <- 0
metrics_df <- data.frame(
  Metric = c("MSE", "RMSE", "MAE", "Residual Std Error", "Adjusted R2", "AIC"),
  Value = unlist(c(pMSE_validate, pRMSE_validate, pMAE_validate, pRSE, pAdjR2, pAIC))
)
# print(pmodel_summary) #  this is a mess
print(metrics_df)

summary_mat <- as.data.frame(pmodel_summary$which)  # Convert selection matrix to a DataFrame

# Ensure variable names are clear
colnames(summary_mat)[1] <- "Intercept"  # Rename the intercept column

# Replace TRUE/FALSE with symbols for better readability
summary_mat[summary_mat == TRUE] <- "T"
summary_mat[summary_mat == FALSE] <- ""

# Convert to flextable
summary_ft <- flextable(summary_mat) |>
  set_table_properties(width = 0.9, layout = "autofit") |>  # Adjust width to fit better
  theme_vanilla() |>                                        # Apply a clean theme
  bold(j = 1, bold = TRUE) |>                               # Bold the first column (Intercept)
  align(align = "center", part = "all") |>                  # Center-align all columns
  border_outer(part = "all",                                # Outer border
  border = officer::fp_border(color = "black",
                              width = 1)) |>               
  border_inner_h(border = officer::fp_border(color = "black", 
                                             width = 0.5)) |>  # Horizontal borders
  border_inner_v(border = officer::fp_border(color = "black", 
                                             width = 0.5)) |>  # Vertical borders
  rotate(j = 1:ncol(summary_mat),
         rotation = "btlr", part = "header")                   # Rotate column names
```

\newpage 
```{r possum-model-selection21, eval=F}
# Print the formatted table
#summary_ft
```




\newpage
## Feature Selection and Model Training
```{r, eval=F}


```

## Model Evaluation

```{r, eval=F}
# Residuals vs. Leverage plot shows potential high-leverage points, which may be influencing the model too much

# Compute evaluation metrics
```

## Further Exploration

```{r, eval=F}
# Additional analysis or research questions 
#[204]
```

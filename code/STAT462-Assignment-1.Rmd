---
title: "STAT462 Assignment 1"
author:
  - Simon Clarke (97211898)
  - David Ewing (82171165)
  - Xia Yu (62380486)
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M')`"

output:
  pdf_document:
    latex_engine: xelatex
    extra_dependencies: ["caption"]
  html_document:
    df_print: paged

geometry: margin=1in

header-includes:
  # - \input{preamble.tex}
  - \usepackage{caption}
  - \usepackage{graphicx}
  - \usepackage{fancyvrb}
  - \RecustomVerbatimEnvironment{verbatim}{Verbatim}{xleftmargin=5mm}
---

```{r setup, include=F,eval=T}
# DEE: This chunk was set up with the aid of ChatGPT
#      The intent is to load updates quietly thus not
#      spending undue time with the logistics of getting 
#      setup. 

options(repos = c(CRAN = "https://cran.stat.auckland.ac.nz/"))

# Required packages
#
required_packages <- c("conflicted", "ggplot2", "dplyr", "class",  
                       "tidyverse", "flextable", "skimr", "GGally",
                       "MASS", "car", "formatR", "mice","tinytex" ,
                       "caret", "gridExtra", "fastDummies" ,"leaps",
                       "extrafont",  "officer", "Metrics","glmnet" ,
                       "knitr", "kableExtra", "cowplot"  ) 

# Install and load missing packages in a single step and quietly
for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  library(pkg, character.only = TRUE)  # Load package after installation check
}

conflict_prefer("filter", "dplyr"); conflict_prefer("select", "dplyr")

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, width = 70, cache=FALSE)

```

```{r common-functions, eval=T, include=F}
# Load and preprocess dataset
# eval=TRUE, as agreed to on 20250313. 
#
load_datasets <- function(zip_path = "../data/datasets.zip") {
  if (file.exists(zip_path)) {
    assign("bdata",          read.csv(unz(zip_path, "braking.csv")), envir = .GlobalEnv)
    assign("income_dateset", read.csv(unz(zip_path, "income.csv")),  envir = .GlobalEnv)
    assign("possums",        read.csv(unz(zip_path, "possums.csv")), envir = .GlobalEnv)
  } else {
    stop(paste(zip_path, "not found."))
  }
}

# This function is used in the question to make income_1 from income_0
#
remove_outliers_IQR <- function(df, col, multiplier = 5, upper_cap = Inf) {        
# Calculate IQR (Quartile distance)
  Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)  # The first quartile
  Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)  # The third quartile
  IQR_value <- Q3 - Q1  # IQR value
  
  # set lower_bound and upper_bound, upper_cap can be manually set
  lower_bound <- Q1 - multiplier * IQR_value  
  upper_bound <- min(Q3 + multiplier * IQR_value, upper_cap)  # upper_cap can be set manually
  # print(upper_bound)
  # filter outliers
  df_clean <- df |> filter(df[[col]] >= lower_bound & df[[col]] <= upper_bound)
  
  return(df_clean)
}

# this function is not used in this version
#
capture_name <- function(mdl) {
  name <- deparse(substitute(mdl))
  return(name)
}


 

# Function to split data into training and test sets
split_data <- function(data, train_ratio = 0.8) {
  # validate train_ratio range
  if (train_ratio <= 0 || train_ratio >= 1) {
  stop("Error: train_ratio must be between 0 and 1 (exclusive).")
}
  # Randomly select the specified percentage of indices for the training set
  train_ind <- sample(1:nrow(data), 
                      size = floor(train_ratio * nrow(data)),
                      replace = FALSE)
  
  # Use the remaining indices for the test set
  test_ind <- setdiff(1:nrow(data), train_ind)
  
  # Create training data using the selected indices
  train_data <- data[train_ind, , drop = FALSE]
  rownames(train_data) <- NULL

  # Create test data using the remaining indices
  test_data <- data[test_ind, , drop = FALSE]
  rownames(test_data) <- NULL
  
  # Return both training and test data as a list
  return(list(train = train_data, test = test_data))
}



skim_flextable <- function(df, col_width = 1.5) {
  df_skim <- skim(df) |> 
    select(skim_variable, skim_type, n_missing) |> 
    rename(Column = skim_variable, Type = skim_type, Missing = n_missing)  # Rename 
  
  ft_skim <- flextable(df_skim) |>
    set_table_properties(width = 1.0, layout = "autofit") |>  # Set global width
    width(j = 1, width = col_width) |>                        # Adjust column 1
    bold(j = 1, bold = TRUE) |>                               # Bold column 1
    theme_vanilla() 
  
  return(ft_skim)
}


```


```{r just-checkin, include=F, eval=F}
# is the folder and file structure 
# constructed correctly? 
dir.exists("../code/")
file.exists("../code/question1.Rmd")
file.exists("../code/question2.Rmd")
file.exists("../code/question3.Rmd")

```

```{r load-dataset, eval=T, include=F}

# Load all Data 
load_datasets() 

```

Question 3 is out of order to resolve conflicts with the response to Question 1 or Question 2. We had chosen early on that each person would deal with one question. Unfortunately Question 3 took the brunt of any quirky results of the other questions. To resolve this, I mave moved Question 3 to the front. 
David Ewing

# Predicting Possum Age

```{r load-question3, child="../code/question3.Rmd", eval=T,cache=FALSE}
```


\newpage
# Braking Distance

```{r load-question1,child="../code/question1.Rmd", eval=T}
```

\newpage
# Filipino Household Income

```{r load-question2, child="../code/question2.Rmd", eval=T}
```


\newpage
# Appendix

```{r load-appendix, child="../code/appendix.Rmd", eval=T}

```